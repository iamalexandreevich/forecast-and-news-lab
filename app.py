import os
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import yaml
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Import custom modules
from modules.stock_analyzer import StockAnalyzer
from modules.telegram_parser import run_telegram_parser
from modules.llm_analyzer import LLMAnalyzer
from modules.forecaster import StockForecaster
from modules.visualizer import Visualizer

# Page configuration
st.set_page_config(
    page_title="–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∞–∫—Ü–∏–π",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)


@st.cache_data(show_spinner=False)
def load_channel_config(path: str = "config/channels.yml") -> list[dict]:
    file_path = Path(path)
    if not file_path.exists():
        return []
    with file_path.open("r", encoding="utf-8") as fh:
        data = yaml.safe_load(fh) or {}
    channels = data.get("channels", data)
    return channels if isinstance(channels, list) else []


@st.cache_data(show_spinner=False)
def load_keywords_config(path: str = "config/keywords.yml") -> list[str]:
    file_path = Path(path)
    if not file_path.exists():
        return []
    with file_path.open("r", encoding="utf-8") as fh:
        data = yaml.safe_load(fh) or {}
    keywords = data.get("keywords", data)
    return [str(keyword) for keyword in keywords] if isinstance(keywords, list) else []


def main():
    st.title("üìà –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∞–∫—Ü–∏–π")
    st.markdown("*–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –Ω–æ–≤–æ—Å—Ç–µ–π Telegram*")

    # Initialize API/model configuration defaults once per session
    default_config = {
        'openai_api_key': os.getenv("LLM_API") or os.getenv("OPENAI_API_KEY", ""),
        'openai_base_url': os.getenv("LLM_BASE_URL") or os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
        'openai_model_name': os.getenv("LLM_MODEL_NAME") or os.getenv("OPENAI_MODEL_NAME", "gpt-5"),
        'telegram_api_id': os.getenv("TELEGRAM_API_ID", ""),
        'telegram_api_hash': os.getenv("TELEGRAM_API_HASH", "").strip("'\""),
        'telegram_phone': os.getenv("TELEGRAM_PHONE", "")
    }
    for key, value in default_config.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # Sidebar configuration
    with st.sidebar:
        st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # Stock symbols input
        st.subheader("–°–∏–º–≤–æ–ª—ã –∞–∫—Ü–∏–π")
        st.info("üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ Yahoo Finance. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã.")
        # Use international alternatives that work with Yahoo Finance
        default_symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "NVDA"]
        stock_symbols = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–∏–º–≤–æ–ª—ã –∞–∫—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
            options=["AAPL", "GOOGL", "MSFT", "TSLA", "NVDA", "META", "AMZN", "NFLX", "BABA", "DIS", "JPM", "V"],
            default=default_symbols
        )
        
        # Custom symbol input
        custom_symbol = st.text_input("–î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–π —Å–∏–º–≤–æ–ª:", placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä, YNDX (–¥–ª—è –Ø–Ω–¥–µ–∫—Å ADR)")
        if custom_symbol and custom_symbol.upper() not in stock_symbols:
            stock_symbols.append(custom_symbol.upper())
        
        # Add expandable section with Russian stock guidance
        with st.expander("üîç –ö–∞–∫ –Ω–∞–π—Ç–∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏?"):
            st.markdown("""
            **–†–æ—Å—Å–∏–π—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ —á–µ—Ä–µ–∑ ADR:**
            - **YNDX** - –Ø–Ω–¥–µ–∫—Å (Yandex ADR)
            - **QIWI** - –ö–∏–≤–∏ (QIWI ADR)
            
            **–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:**
            - **BABA** - Alibaba (–ö–∏—Ç–∞–π)
            - **PDD** - PDD Holdings
            - **NIO** - NIO Inc.
            
            *–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ü—Ä—è–º—ã–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ (.ME) –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ Yahoo Finance –∏–∑-–∑–∞ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π.*
            """)
        
        # Telegram channels input
        st.subheader("Telegram –∫–∞–Ω–∞–ª—ã")
        config_channels_sidebar = load_channel_config()
        if config_channels_sidebar:
            st.caption("üìÅ –û—Å–Ω–æ–≤–Ω–æ–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ `config/channels.yml`")
        manual_channels_raw = st.text_area(
            "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞–Ω–∞–ª—ã (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):",
            value="",
            placeholder="investfuture\ntbank_news",
            help="–ö–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Å @ –∏–ª–∏ –±–µ–∑"
        ).split('\n')
        manual_channels = [ch.strip().lstrip('@') for ch in manual_channels_raw if ch.strip()]
        
        # Time period settings
        st.subheader("–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
        analysis_period = st.selectbox(
            "–ü–µ—Ä–∏–æ–¥ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö:",
            options=["1y", "2y", "5y"],
            index=1
        )
        
        news_days = st.slider(
            "–î–Ω–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π:",
            min_value=1,
            max_value=365,
            value=30  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 7 –¥–æ 30 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        )
        
        # API configuration inputs
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ LLM")
        openai_model_name = st.text_input(
            "–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏",
            value=st.session_state.get('openai_model_name', "gpt-5"),
            help="–ù–∞–ø—Ä–∏–º–µ—Ä, gpt-5, gpt-4o, llama3 –∏ —Ç.–¥."
        )
        openai_base_url = st.text_input(
            "–ë–∞–∑–æ–≤—ã–π URL API",
            value=st.session_state.get('openai_base_url', "https://api.openai.com/v1"),
            help="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç, –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é LLM-–ø–ª–∞—Ç—Ñ–æ—Ä–º—É"
        )
        openai_key = st.text_input(
            "OpenAI API Key",
            value=st.session_state.get('openai_api_key', ""),
            type="password",
            help="–ö–ª—é—á –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏ (–Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ)"
        )

        st.subheader("Telegram API")
        telegram_api_id = st.text_input(
            "API ID",
            value=st.session_state.get('telegram_api_id', ""),
            help="–ß–∏—Å–ª–æ–≤–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Telegram"
        )
        telegram_api_hash = st.text_input(
            "API Hash",
            value=st.session_state.get('telegram_api_hash', ""),
            help="–°–µ–∫—Ä–µ—Ç–Ω—ã–π hash –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Telegram"
        )
        telegram_phone = st.text_input(
            "–¢–µ–ª–µ—Ñ–æ–Ω (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)",
            value=st.session_state.get('telegram_phone', ""),
            help="–¢–µ–ª–µ—Ñ–æ–Ω, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–∏–≤—è–∑–∞–Ω –∞–∫–∫–∞—É–Ω—Ç Telegram"
        )

        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API"):
            st.session_state.openai_model_name = openai_model_name.strip() or "gpt-5"
            st.session_state.openai_base_url = openai_base_url.strip() or "https://api.openai.com/v1"
            st.session_state.openai_api_key = openai_key.strip()
            st.session_state.telegram_api_id = telegram_api_id.strip()
            st.session_state.telegram_api_hash = telegram_api_hash.strip()
            st.session_state.telegram_phone = telegram_phone.strip()
            st.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ API –æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏")

        # API status indicators
        if st.session_state.openai_api_key:
            st.success("‚úÖ –ö–ª—é—á OpenAI API –∑–∞–≥—Ä—É–∂–µ–Ω")
            st.info(f"üîó –ë–∞–∑–æ–≤—ã–π URL: {st.session_state.openai_base_url}")
            st.caption(f"üß† –ú–æ–¥–µ–ª—å: {st.session_state.openai_model_name}")
        else:
            st.error("‚ùå –ö–ª—é—á OpenAI API –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

        if st.session_state.telegram_api_id and st.session_state.telegram_api_hash:
            st.success("‚úÖ Telegram API –ø–æ–¥–∫–ª—é—á–µ–Ω")
        else:
            st.warning("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ Telegram API ID –∏ API Hash")

    # Main content tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä –ê–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π", 
        "üì± –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π", 
        "üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è", 
        "üîÆ –ü—Ä–æ–≥–Ω–æ–∑", 
        "üìã –û—Ç—á–µ—Ç"
    ])
    
    # Initialize components
    if 'stock_analyzer' not in st.session_state:
        st.session_state.stock_analyzer = StockAnalyzer()

    llm_config_signature = (
        st.session_state.get('openai_api_key'),
        st.session_state.get('openai_base_url'),
        st.session_state.get('openai_model_name')
    )
    if (
        'llm_analyzer' not in st.session_state or
        st.session_state.get('llm_config_signature') != llm_config_signature
    ):
        st.session_state.llm_analyzer = LLMAnalyzer(
            api_key=st.session_state.get('openai_api_key'),
            base_url=st.session_state.get('openai_base_url'),
            model_name=st.session_state.get('openai_model_name')
        )
        st.session_state.llm_config_signature = llm_config_signature

    if 'forecaster' not in st.session_state:
        st.session_state.forecaster = StockForecaster()
    if 'visualizer' not in st.session_state:
        st.session_state.visualizer = Visualizer()
    
    # Tab 1: Stock Analysis
    with tab1:
        st.header("üìä –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π")

        if not stock_symbols:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª –∞–∫—Ü–∏–∏ –∏–∑ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        else:
            # Fetch stock data button
            if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –∞–∫—Ü–∏—è—Ö", type="primary"):
                with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ –∞–∫—Ü–∏—è—Ö..."):
                    success = st.session_state.stock_analyzer.fetch_stock_data(stock_symbols, analysis_period)
                    if success:
                        st.success(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ {len(stock_symbols)} –∞–∫—Ü–∏—è–º")
                        st.session_state.stock_data_loaded = True
                    else:
                        st.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ –∞–∫—Ü–∏—è—Ö")
        
        # Display stock analysis if data is loaded
        if hasattr(st.session_state, 'stock_data_loaded') and st.session_state.stock_data_loaded:
            
            # Stock selection for detailed analysis
            selected_stock = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ü–∏—é –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:", stock_symbols)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Price history chart
                if selected_stock in st.session_state.stock_analyzer.stock_data:
                    stock_data = st.session_state.stock_analyzer.stock_data[selected_stock]
                    fig_price = st.session_state.visualizer.plot_stock_price_history(stock_data, selected_stock)
                    st.plotly_chart(fig_price, width='stretch')
                    
                    # Price distribution analysis
                    fig_dist = st.session_state.visualizer.plot_price_distribution(stock_data, selected_stock)
                    st.plotly_chart(fig_dist, width='stretch')
            
            with col2:
                # Statistics table
                stats = st.session_state.stock_analyzer.calculate_statistics(selected_stock)
                if stats:
                    stats_df = st.session_state.visualizer.display_statistics_table(stats, selected_stock)
                    st.subheader(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ {selected_stock}")
                    st.dataframe(stats_df, hide_index=True)
            
            # Top movements analysis
            st.subheader("–¢–æ–ø 20 —Ü–µ–Ω–æ–≤—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π")
            top_rises, top_falls = st.session_state.stock_analyzer.find_top_movements(selected_stock)
            
            if top_rises is not None and top_falls is not None:
                fig_movements = st.session_state.visualizer.plot_top_movements(top_rises, top_falls, selected_stock)
                st.plotly_chart(fig_movements, width='stretch')
                
                # Display top movements tables
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("üìà –¢–æ–ø 20 —Ä–æ—Å—Ç–æ–≤")
                    rises_display = top_rises[['Daily_Change_Pct', 'Volume', 'Close']].round(4)
                    st.dataframe(rises_display)
                
                with col2:
                    st.subheader("üìâ –¢–æ–ø 20 –ø–∞–¥–µ–Ω–∏–π")
                    falls_display = top_falls[['Daily_Change_Pct', 'Volume', 'Close']].round(4)
                    st.dataframe(falls_display)
    
    # Tab 2: News Sentiment Analysis
    with tab2:
        st.header("üì± –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –Ω–æ–≤–æ—Å—Ç–µ–π Telegram")

        config_channels_tab = load_channel_config()
        enabled_channels = [cfg for cfg in config_channels_tab if cfg.get("enabled", True)]
        channel_options = [cfg.get("username", "").lstrip('@') for cfg in enabled_channels if cfg.get("username")]
        channel_labels = {
            cfg.get("username", "").lstrip('@'): f"{cfg.get('title') or cfg.get('username')} (@{cfg.get('username', '').lstrip('@')})"
            for cfg in enabled_channels
            if cfg.get("username")
        }

        selected_config_channels = st.multiselect(
            "–ö–∞–Ω–∞–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:",
            options=channel_options,
            default=channel_options[: min(5, len(channel_options))],
            format_func=lambda username: channel_labels.get(username, f"@{username}"),
            help="–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–±–ª–∏—á–Ω—ã–µ Telegram-–∫–∞–Ω–∞–ª—ã –∏–∑ `config/channels.yml`"
        )

        if manual_channels:
            st.caption("‚ûï –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∏–∑ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏: " + ", ".join(f"@{c}" for c in manual_channels))

        combined_usernames = set(selected_config_channels)
        combined_usernames.update(manual_channels)

        selected_channel_payload = []
        for cfg in enabled_channels:
            username = cfg.get("username", "").lstrip('@')
            if username and username in combined_usernames:
                payload = cfg.copy()
                payload["username"] = username
                selected_channel_payload.append(payload)

        existing_usernames = {item["username"] for item in selected_channel_payload}
        for manual in manual_channels:
            if manual not in existing_usernames:
                selected_channel_payload.append({"username": manual, "title": manual, "enabled": True})

        keywords_catalog = load_keywords_config()
        selected_keywords = st.multiselect(
            "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:",
            options=keywords_catalog,
            default=keywords_catalog,
            help="–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π)"
        )
        custom_keywords_input = st.text_input(
            "–î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é:",
            value="",
            placeholder="–¥–∏–≤–∏–¥–µ–Ω–¥—ã, buyback, guidance"
        )
        if custom_keywords_input:
            extra_keywords = [kw.strip() for kw in custom_keywords_input.replace('\n', ',').split(',') if kw.strip()]
            selected_keywords = sorted({*selected_keywords, *extra_keywords})

        show_all_messages = st.checkbox(
            "–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤)",
            value=False,
            help="–û—Ç–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ —Ç–∏–∫–µ—Ä–∞–º –∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)."
        )
        if show_all_messages:
            st.caption("‚ö†Ô∏è –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Äî –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")

        st.caption(f"üìÜ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Å–±–æ—Ä –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {news_days} –¥–Ω.")

        api_id = st.session_state.get('telegram_api_id')
        api_hash = st.session_state.get('telegram_api_hash')
        phone = st.session_state.get('telegram_phone')

        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–µ—Å—Å–∏–∏ Telegram (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è)
        col1, col2 = st.columns([3, 1])
        with col1:
            fetch_news_btn = st.button("üîç –°–æ–±—Ä–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ Telegram", type="primary")
        with col2:
            if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å —Å–µ—Å—Å–∏—é"):
                # –û—á–∏—â–∞–µ–º –≤—Å–µ —Ñ–ª–∞–≥–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                keys_to_delete = [
                    'telegram_entered_code',
                    'telegram_phone_code_hash',
                    'telegram_auth_in_progress'
                ]
                for key in keys_to_delete:
                    if key in st.session_state:
                        del st.session_state[key]

                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏
                session_file = Path("data/telegram/stock_forecasting_session.session")
                if session_file.exists():
                    session_file.unlink()
                st.success("–°–µ—Å—Å–∏—è —Å–±—Ä–æ—à–µ–Ω–∞. –ù–∞–∂–º–∏—Ç–µ '–°–æ–±—Ä–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏' –¥–ª—è –Ω–æ–≤–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.")
                st.rerun()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        if 'telegram_auth_in_progress' not in st.session_state:
            st.session_state.telegram_auth_in_progress = False

        if fetch_news_btn:
            st.session_state.telegram_auth_in_progress = True

        if st.session_state.telegram_auth_in_progress:
            if not selected_channel_payload:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–Ω–∞–ª –∏–∑ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤—Ä—É—á–Ω—É—é –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
                st.session_state.telegram_auth_in_progress = False
            elif not api_id or not api_hash:
                st.error("–£–∫–∞–∂–∏—Ç–µ Telegram API ID –∏ API Hash –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
                st.session_state.telegram_auth_in_progress = False
            else:
                st.info("üí° –ï—Å–ª–∏ —É–≤–∏–¥–∏—Ç–µ QR ‚Äî –æ—Ç—Å–∫–∞–Ω–∏—Ä—É–π—Ç–µ –µ–≥–æ –≤ Telegram: Settings ‚Üí Devices ‚Üí Link Desktop Device")
                channels_text = ", ".join(f"@{name}" for name in sorted(combined_usernames)) or "‚Äî"
                progress_bar = st.progress(0, text="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞‚Ä¶")

                # –ü–∞–Ω–µ–ª—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª–æ–≥–æ–≤
                log_container = st.expander("üìã –õ–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏", expanded=True)
                with log_container:
                    st.write("üîç **Session state —Ñ–ª–∞–≥–∏:**")
                    st.write(f"- telegram_phone_code_hash: {'—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚úÖ' if st.session_state.get('telegram_phone_code_hash') else '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚ùå'}")
                    st.write(f"- telegram_entered_code: {'—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚úÖ' if st.session_state.get('telegram_entered_code') else '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚ùå'}")
                    st.write(f"- telegram_auth_in_progress: {st.session_state.get('telegram_auth_in_progress', False)}")

                # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–æ–≥ —Å–æ–±—ã—Ç–∏–π —Å —Ä–µ–∞–ª—å–Ω–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
                detailed_logs = st.expander("üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ —Å–±–æ—Ä–∞", expanded=True)
                event_logs = []

                def log_event(msg: str):
                    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –ª–æ–≥ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π"""
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    log_msg = f"[{timestamp}] {msg}"
                    event_logs.append(log_msg)
                    # –í—ã–≤–æ–¥–∏–º –ª–æ–≥–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
                    with detailed_logs:
                        st.text(log_msg)

                # –°–æ–∑–¥–∞—ë–º callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                total_channels = len(combined_usernames)
                completed_channels = 0
                channel_stats = {}

                def progress_callback(username: str, status_type: str, count: int, error_msg: str):
                    nonlocal completed_channels

                    if status_type == "start":
                        log_event(f"üéØ @{username}: –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–Ω–∞–ª–∞")
                        log_event(f"üì° @{username}: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram...")
                        status.write(f"üì• @{username}: –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
                    elif status_type == "complete":
                        completed_channels += 1
                        channel_stats[username] = count
                        log_event(f"‚úÖ @{username}: –ó–ê–í–ï–†–®–ï–ù–û - —Å–æ–±—Ä–∞–Ω–æ {count} —Å–æ–æ–±—â–µ–Ω–∏–π")
                        status.write(f"‚úÖ @{username}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π")
                        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                        progress_pct = int((completed_channels / total_channels) * 70) + 20  # 20-90%
                        progress_bar.progress(progress_pct, text=f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {completed_channels}/{total_channels} –∫–∞–Ω–∞–ª–æ–≤")
                    elif status_type == "waiting":
                        log_event(f"‚è∞ @{username}: FloodWait - –æ–∂–∏–¥–∞–Ω–∏–µ {count} —Å–µ–∫...")
                        status.write(f"‚è∞ @{username}: –æ–∂–∏–¥–∞–Ω–∏–µ {count} —Å–µ–∫...")
                    elif status_type == "error":
                        log_event(f"‚ùå @{username}: –û–®–ò–ë–ö–ê - {error_msg}")
                        status.write(f"‚ùå @{username}: {error_msg}")

                parser_stock_symbols = stock_symbols if not show_all_messages else []
                parser_keywords = selected_keywords if not show_all_messages else None

                with st.status("–°–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram", expanded=True) as status:
                    status.write(f"üìã –ö–∞–Ω–∞–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {channels_text}")
                    status.write(f"üìÖ –ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {news_days} –¥–Ω–µ–π")
                    if show_all_messages:
                        status.write("üéØ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
                    else:
                        status.write(f"üéØ –¢–∏–∫–µ—Ä—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {', '.join(stock_symbols) if stock_symbols else '–≤—Å–µ'}")
                        if selected_keywords:
                            status.write(f"üîç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {len(selected_keywords)} —à—Ç.")
                    progress_bar.progress(20, text="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞‚Ä¶")
                    try:
                        log_event("=" * 60)
                        log_event("üöÄ –ó–ê–ü–£–°–ö –ü–†–û–¶–ï–°–°–ê –ü–ê–†–°–ò–ù–ì–ê")
                        log_event("=" * 60)
                        log_event(f"üìä –í—Å–µ–≥–æ –∫–∞–Ω–∞–ª–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(combined_usernames)}")
                        log_event(f"üìÖ –ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞: {news_days} –¥–Ω–µ–π")
                        status.write("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –∫–ª–∏–µ–Ω—Ç–∞...")
                        result_df = run_telegram_parser(
                            channel_list=selected_channel_payload,
                            stock_symbols=parser_stock_symbols,
                            days_back=news_days,
                            api_id=api_id,
                            api_hash=api_hash,
                            phone=phone,
                            keywords=parser_keywords or None,
                            ui=st,
                            progress_callback=progress_callback,
                        )
                        progress_bar.progress(90, text="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤‚Ä¶")
                        log_event("=" * 60)
                        log_event("üìä –û–ë–†–ê–ë–û–¢–ö–ê –ò –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
                        log_event("=" * 60)
                    except RuntimeError as exc:
                        # RuntimeError –æ–±—ã—á–Ω–æ –æ–∑–Ω–∞—á–∞–µ—Ç "–æ–∂–∏–¥–∞–Ω–∏–µ –≤–≤–æ–¥–∞ –∫–æ–¥–∞"
                        if "Waiting for code input" in str(exc):
                            progress_bar.progress(50, text="‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∫–æ–¥–∞...")
                            status.update(label="–û–∂–∏–¥–∞–Ω–∏–µ –≤–≤–æ–¥–∞ –∫–æ–¥–∞", state="running")
                            status.write("‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥ –∏–∑ Telegram –≤—ã—à–µ")
                            with log_container:
                                st.warning("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≤–≤–æ–¥–∞ –∫–æ–¥–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                            # –ù–ï —Å–±—Ä–∞—Å—ã–≤–∞–µ–º telegram_auth_in_progress, —á—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ—Å–ª–µ –≤–≤–æ–¥–∞ –∫–æ–¥–∞
                        else:
                            st.session_state.telegram_messages = pd.DataFrame()
                            st.session_state.telegram_auth_in_progress = False
                            progress_bar.progress(100, text="–û—à–∏–±–∫–∞")
                            status.update(label="–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏", state="error")
                            status.write(str(exc))
                            st.error(f"‚ùå –û—à–∏–±–∫–∞: {exc}")
                            with log_container:
                                st.error(f"RuntimeError: {exc}")
                    except Exception as exc:
                        st.session_state.telegram_messages = pd.DataFrame()
                        st.session_state.telegram_auth_in_progress = False
                        progress_bar.progress(100, text="–û—à–∏–±–∫–∞")
                        status.update(label="–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ", state="error")
                        status.write(str(exc))
                        st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Telegram: {exc}")
                        with log_container:
                            st.error(f"Exception: {type(exc).__name__}: {exc}")
                    else:
                        # –£—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                        st.session_state.telegram_auth_in_progress = False
                        if not result_df.empty:
                            messages_df = result_df.copy()
                            messages_df["date"] = pd.to_datetime(messages_df["date_utc"], utc=True)
                            messages_df["channel"] = messages_df["channel_title"].fillna(messages_df["channel_username"])
                            messages_df["message_id"] = messages_df["id"]
                            st.session_state.telegram_messages = messages_df

                            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                            total_collected = sum(channel_stats.values())
                            log_event("=" * 60)
                            log_event("‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–Å–ù")
                            log_event("=" * 60)
                            log_event(f"üì¶ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ RAW: {total_collected} —Å–æ–æ–±—â–µ–Ω–∏–π")
                            log_event(f"üîç –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(messages_df)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                            log_event(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {len(channel_stats)}")
                            log_event("")
                            log_event("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º:")
                            for ch_name, ch_count in sorted(channel_stats.items(), key=lambda x: x[1], reverse=True):
                                log_event(f"  ‚Ä¢ @{ch_name}: {ch_count} —Å–æ–æ–±—â–µ–Ω–∏–π")
                            log_event("=" * 60)

                            status.update(label="–°–±–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω", state="complete")
                            status.write(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(messages_df)} —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
                            status.write(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º:")
                            for ch_name, ch_count in sorted(channel_stats.items(), key=lambda x: x[1], reverse=True):
                                status.write(f"  ‚Ä¢ @{ch_name}: {ch_count} —Å–æ–æ–±—â–µ–Ω–∏–π")

                            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(messages_df)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {len(combined_usernames)} –∫–∞–Ω–∞–ª–æ–≤")
                        else:
                            st.session_state.telegram_messages = result_df
                            log_event("=" * 60)
                            log_event("‚ö†Ô∏è –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–Å–ù - –ù–ï–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
                            log_event("=" * 60)
                            log_event("‚ö†Ô∏è –§–∏–ª—å—Ç—Ä—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
                            log_event("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
                            log_event("  - –£–≤–µ–ª–∏—á–∏—Ç—å –ø–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞ (days_back)")
                            log_event("  - –£–±—Ä–∞—Ç—å –∏–ª–∏ –æ—Å–ª–∞–±–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ —Ç–∏–∫–µ—Ä–∞–º")
                            log_event("  - –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–∞–Ω–∞–ª–æ–≤")
                            status.update(label="–°–±–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω", state="complete")
                            status.write("–§–∏–ª—å—Ç—Ä—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Å–ª–∞–±–∏—Ç—å —É—Å–ª–æ–≤–∏—è.")
                            st.warning("–°–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –£–≤–µ–ª–∏—á—å—Ç–µ –æ–∫–Ω–æ –ø–æ–∏—Å–∫–∞ –∏–ª–∏ —É–±–µ—Ä–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã.")
                        progress_bar.progress(100, text="–ì–æ—Ç–æ–≤–æ")

        news_available = hasattr(st.session_state, 'telegram_messages') and not st.session_state.telegram_messages.empty

        if news_available:
            news_df = st.session_state.telegram_messages
            st.subheader("–°–≤–æ–¥–∫–∞ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
            col1, col2, col3 = st.columns(3)
            col1.metric("–°–æ–æ–±—â–µ–Ω–∏–π", len(news_df))
            col2.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤", news_df['channel_username'].nunique())
            if 'date_utc' in news_df.columns:
                date_min = pd.to_datetime(news_df['date_utc']).min()
                date_max = pd.to_datetime(news_df['date_utc']).max()
                if pd.notna(date_min) and pd.notna(date_max):
                    col3.metric("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", f"{date_min.strftime('%d.%m %H:%M')} ‚Äì {date_max.strftime('%d.%m %H:%M')}")
            preview_cols = [col for col in ['date_utc', 'channel', 'text', 'tickers', 'links'] if col in news_df.columns]
            st.dataframe(news_df[preview_cols].tail(25), width='stretch')

        # Analyze sentiment if messages are available
        if news_available:
            if st.button("üß† –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é LLM", type="secondary"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM..."):
                    sentiment_results = st.session_state.llm_analyzer.analyze_batch_messages(
                        st.session_state.telegram_messages,
                        stock_symbols
                    )
                    if not sentiment_results.empty:
                        st.session_state.sentiment_analysis = sentiment_results
                        st.success(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–ª—è {len(sentiment_results)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                    else:
                        st.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")

            if hasattr(st.session_state, 'sentiment_analysis') and not st.session_state.sentiment_analysis.empty:
                sentiment_df = st.session_state.sentiment_analysis

                fig_sentiment = st.session_state.visualizer.plot_sentiment_analysis(sentiment_df)
                if fig_sentiment:
                    st.plotly_chart(fig_sentiment, width='stretch')

                st.subheader("–°–≤–æ–¥–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    positive_count = len(sentiment_df[sentiment_df['sentiment'] == 'positive'])
                    st.metric("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", positive_count)

                with col2:
                    negative_count = len(sentiment_df[sentiment_df['sentiment'] == 'negative'])
                    st.metric("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", negative_count)

                with col3:
                    neutral_count = len(sentiment_df[sentiment_df['sentiment'] == 'neutral'])
                    st.metric("–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏", neutral_count)

                with col4:
                    avg_confidence = sentiment_df['confidence'].mean()
                    st.metric("–°—Ä. —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{avg_confidence:.2f}")

                st.subheader("–ù–µ–¥–∞–≤–Ω–∏–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
                display_cols = ['date', 'channel', 'sentiment', 'confidence', 'impact_strength', 'summary']
                available_cols = [col for col in display_cols if col in sentiment_df.columns]
                st.dataframe(sentiment_df[available_cols].head(10))

        else:
            st.info("–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–∞–Ω–∞–ª—ã –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.")
    
    # Tab 3: Correlation Analysis
    with tab3:
        st.header("üîó –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∞–∫—Ü–∏–π")
        
        # Check if we have both stock data and sentiment analysis
        has_stock_data = hasattr(st.session_state, 'stock_data_loaded') and st.session_state.stock_data_loaded
        has_sentiment = hasattr(st.session_state, 'sentiment_analysis') and not st.session_state.sentiment_analysis.empty
        
        if not has_stock_data:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –æ –∞–∫—Ü–∏—è—Ö (–≤–∫–ª–∞–¥–∫–∞ –ê–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π)")
        elif not has_sentiment:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π (–≤–∫–ª–∞–¥–∫–∞ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π)")
        else:
            # Select stock for correlation analysis
            correlation_stock = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ü–∏—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:", stock_symbols, key="corr_stock")

            if st.button("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é", type="primary"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∏ –¥–≤–∏–∂–µ–Ω–∏—è–º–∏ –∞–∫—Ü–∏–π..."):
                    correlation_df = st.session_state.llm_analyzer.correlate_news_with_stock_movements(
                    st.session_state.sentiment_analysis,
                    st.session_state.stock_analyzer,
                    correlation_stock
                )
                
                if correlation_df is not None and not correlation_df.empty:
                    st.session_state.correlation_results = correlation_df
                    st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(correlation_df)} —Ç–æ—á–µ–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
                else:
                    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")
        
        # Display correlation results
        if hasattr(st.session_state, 'correlation_results') and not st.session_state.correlation_results.empty:
            correlation_df = st.session_state.correlation_results
            
            # Correlation visualization
            fig_correlation = st.session_state.visualizer.plot_correlation_analysis(correlation_df)
            if fig_correlation:
                st.plotly_chart(fig_correlation, width='stretch')
            
            # Correlation metrics
            st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                sentiment_stock_corr = pd.Series(correlation_df['sentiment_score']).corr(pd.Series(correlation_df['stock_change_pct']))
                st.metric("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ-—Ü–µ–Ω–∞", f"{sentiment_stock_corr:.3f}")
            
            with col2:
                avg_impact = correlation_df['impact_strength'].mean()
                st.metric("–°—Ä–µ–¥–Ω—è—è —Å–∏–ª–∞ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è", f"{avg_impact:.1f}")
            
            with col3:
                same_day_corr = correlation_df[correlation_df['days_offset'] == 0]
                if not same_day_corr.empty:
                    same_day_strength = pd.Series(same_day_corr['sentiment_score']).corr(pd.Series(same_day_corr['stock_change_pct']))
                    st.metric("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å", f"{same_day_strength:.3f}")
                else:
                    st.metric("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å", "N/A")
            
            with col4:
                high_confidence = correlation_df[correlation_df['confidence'] > 0.7]
                st.metric("–¢–æ—á–∫–∏ –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏", len(high_confidence))
            
            # Correlation data table
            st.subheader("–î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
            display_cols = ['news_date', 'stock_date', 'days_offset', 'sentiment_score', 
                           'stock_change_pct', 'confidence', 'impact_strength']
            available_cols = [col for col in display_cols if col in correlation_df.columns]
            st.dataframe(correlation_df[available_cols])
    
    # Tab 4: Forecasting
    with tab4:
        st.header("üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ü–∏–π")
        
        # Check if required data is available
        has_stock_data = hasattr(st.session_state, 'stock_data_loaded') and st.session_state.stock_data_loaded
        
        if not has_stock_data:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –æ –∞–∫—Ü–∏—è—Ö (–≤–∫–ª–∞–¥–∫–∞ –ê–Ω–∞–ª–∏–∑ –∞–∫—Ü–∏–π)")
        else:
            # Forecast parameters
            col1, col2 = st.columns([2, 1])

            with col1:
                forecast_stock = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ü–∏—é –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞:", stock_symbols, key="forecast_stock")

            with col2:
                forecast_days = st.slider("–î–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞:", min_value=30, max_value=365, value=90)

            # Train model and generate forecast
            if st.button("üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑", type="primary"):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è..."):
                    # Prepare data for training
                    stock_data = st.session_state.stock_analyzer.stock_data[forecast_stock]

                    # Use sentiment data if available
                    sentiment_data = None
                    if hasattr(st.session_state, 'sentiment_analysis') and not st.session_state.sentiment_analysis.empty:
                        sentiment_data = st.session_state.sentiment_analysis

                    prepared_data = st.session_state.forecaster.prepare_features(stock_data, sentiment_data)

                    if prepared_data is not None:
                        # Train the model
                        training_success = st.session_state.forecaster.train_model(prepared_data)

                        if training_success:
                            # Generate forecast
                            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞..."):
                                recent_data = st.session_state.stock_analyzer.get_recent_data(forecast_stock, 30)
                                recent_prepared = st.session_state.forecaster.prepare_features(recent_data, sentiment_data)

                                if recent_prepared is not None:
                                    forecast_results = st.session_state.forecaster.generate_forecast(
                                        recent_prepared, forecast_days
                                    )

                                    if forecast_results is not None:
                                        st.session_state.forecast_results = forecast_results
                                        st.session_state.forecast_stock_data = stock_data
                                        st.success("–ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!")
                                    else:
                                        st.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞")
                        else:
                            st.error("–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
                    else:
                        st.error("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞")
        
            # Display forecast results
            if hasattr(st.session_state, 'forecast_results') and st.session_state.forecast_results is not None:
                forecast_df = st.session_state.forecast_results
                historical_data = st.session_state.forecast_stock_data
            
                # Forecast visualization
                fig_forecast = st.session_state.visualizer.plot_forecast(historical_data, forecast_df, forecast_stock)
                st.plotly_chart(fig_forecast, width='stretch')
            
                # Forecast summary
                st.subheader("Forecast Summary")
                col1, col2, col3, col4 = st.columns(4)
            
                current_price = historical_data['Close'].iloc[-1]
                final_predicted_price = forecast_df['Predicted_Price'].iloc[-1]
                total_return = ((final_predicted_price - current_price) / current_price) * 100
            
                with col1:
                    st.metric("Current Price", f"${current_price:.2f}")

                with col2:
                    st.metric("Predicted Price", f"${final_predicted_price:.2f}")

                with col3:
                    st.metric("Expected Return", f"{total_return:.2f}%")

                with col4:
                    max_price = forecast_df['Predicted_Price'].max()
                    st.metric("Max Predicted", f"${max_price:.2f}")
            
                # Feature importance
                feature_importance = st.session_state.forecaster.get_feature_importance()
                if feature_importance is not None:
                    st.subheader("Model Feature Importance")
                    st.bar_chart(feature_importance.set_index('Feature')['Importance'])
            
                # LLM-based forecast analysis
            if st.button("üß† Generate LLM Forecast Analysis"):
                with st.spinner("Generating AI-powered forecast analysis..."):
                    # Prepare historical patterns summary
                    stats = st.session_state.stock_analyzer.calculate_statistics(forecast_stock)
                    rise_patterns, fall_patterns = st.session_state.stock_analyzer.identify_patterns_before_movements(forecast_stock)
                    
                    # Prepare sentiment summary
                    sentiment_summary = None
                    if hasattr(st.session_state, 'sentiment_analysis') and not st.session_state.sentiment_analysis.empty:
                        sentiment_df = st.session_state.sentiment_analysis
                        sentiment_summary = {
                            'total_messages': len(sentiment_df),
                            'positive_ratio': len(sentiment_df[sentiment_df['sentiment'] == 'positive']) / len(sentiment_df),
                            'negative_ratio': len(sentiment_df[sentiment_df['sentiment'] == 'negative']) / len(sentiment_df),
                            'avg_confidence': sentiment_df['confidence'].mean(),
                            'avg_impact_strength': sentiment_df['impact_strength'].mean()
                        }
                    
                    llm_analysis = st.session_state.llm_analyzer.generate_forecast_analysis(
                        {'stats': stats, 'patterns': {'rises': rise_patterns, 'falls': fall_patterns}},
                        sentiment_summary,
                        forecast_stock
                    )
                    
                    if llm_analysis:
                        st.session_state.llm_forecast_analysis = llm_analysis
                        
                        # Display LLM analysis
                        st.subheader("üß† AI Forecast Analysis")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**Quarter Outlook:**", llm_analysis.get('quarter_outlook', 'N/A'))
                            st.write("**Confidence Level:**", f"{llm_analysis.get('confidence_level', 0):.2f}")
                            
                            target_range = llm_analysis.get('target_price_range', {})
                            if target_range:
                                st.write("**Target Price Range:**", f"${target_range.get('min', 0):.2f} - ${target_range.get('max', 0):.2f}")
                        
                        with col2:
                            correlation_strength = llm_analysis.get('sentiment_correlation_strength', 0)
                            st.write("**Sentiment Correlation:**", f"{correlation_strength:.2f}")
                            st.write("**Time Horizon:**", llm_analysis.get('time_horizon', 'Q1 2026'))
                        
                        # Risks and opportunities
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader("Key Risks")
                            risks = llm_analysis.get('key_risks', [])
                            for risk in risks:
                                st.write(f"‚Ä¢ {risk}")
                        
                        with col2:
                            st.subheader("Key Opportunities")
                            opportunities = llm_analysis.get('key_opportunities', [])
                            for opp in opportunities:
                                st.write(f"‚Ä¢ {opp}")
                        
                        # Forecast summary
                        st.subheader("Forecast Summary")
                        summary = llm_analysis.get('forecast_summary', '')
                        st.write(summary)
    
    # Tab 5: Summary Report
    with tab5:
        st.header("üìã Analysis Summary Report")
        
        # Check what analyses have been completed
        has_stock_data = hasattr(st.session_state, 'stock_data_loaded') and st.session_state.stock_data_loaded
        has_sentiment = hasattr(st.session_state, 'sentiment_analysis')
        has_correlation = hasattr(st.session_state, 'correlation_results')
        has_forecast = hasattr(st.session_state, 'forecast_results')
        has_llm_analysis = hasattr(st.session_state, 'llm_forecast_analysis')
        
        # Analysis completion status
        st.subheader("Analysis Status")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            status = "‚úÖ Complete" if has_stock_data else "‚ùå Pending"
            st.write(f"**Stock Analysis:** {status}")
        
        with col2:
            status = "‚úÖ Complete" if has_sentiment else "‚ùå Pending"
            st.write(f"**News Sentiment:** {status}")
        
        with col3:
            status = "‚úÖ Complete" if has_correlation else "‚ùå Pending"
            st.write(f"**Correlation:** {status}")
        
        with col4:
            status = "‚úÖ Complete" if has_forecast else "‚ùå Pending"
            st.write(f"**Forecasting:** {status}")
        
        st.divider()
        
        # Key findings summary
        if has_stock_data:
            st.subheader("üìä Key Stock Analysis Findings")
            
            for symbol in stock_symbols:
                if symbol in st.session_state.stock_analyzer.stock_data:
                    stats = st.session_state.stock_analyzer.calculate_statistics(symbol)
                    if stats:
                        with st.expander(f"{symbol} Summary"):
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Mean Daily Return", f"{stats['mean']:.4f}%")
                                st.metric("Volatility", f"{stats['std']:.4f}%")
                            with col2:
                                st.metric("95th Percentile", f"{stats['quantile_95']:.4f}%")
                                st.metric("5th Percentile", f"{stats['quantile_05']:.4f}%")
                            with col3:
                                st.metric("Skewness", f"{stats['skewness']:.4f}")
                                st.metric("Kurtosis", f"{stats['kurtosis']:.4f}")
        
        # Sentiment summary
        if has_sentiment and not st.session_state.sentiment_analysis.empty:
            st.subheader("üì± News Sentiment Summary")
            sentiment_df = st.session_state.sentiment_analysis
            
            col1, col2, col3 = st.columns(3)
            with col1:
                positive_pct = len(sentiment_df[sentiment_df['sentiment'] == 'positive']) / len(sentiment_df) * 100
                st.metric("Positive News", f"{positive_pct:.1f}%")
            
            with col2:
                negative_pct = len(sentiment_df[sentiment_df['sentiment'] == 'negative']) / len(sentiment_df) * 100
                st.metric("Negative News", f"{negative_pct:.1f}%")
            
            with col3:
                avg_confidence = sentiment_df['confidence'].mean()
                st.metric("Average Confidence", f"{avg_confidence:.2f}")
        
        # Correlation summary
        if has_correlation and not st.session_state.correlation_results.empty:
            st.subheader("üîó Correlation Summary")
            correlation_df = st.session_state.correlation_results
            
            col1, col2 = st.columns(2)
            with col1:
                overall_corr = pd.Series(correlation_df['sentiment_score']).corr(pd.Series(correlation_df['stock_change_pct']))
                st.metric("Overall Correlation", f"{overall_corr:.3f}")
            
            with col2:
                high_confidence = len(correlation_df[correlation_df['confidence'] > 0.7])
                st.metric("High Confidence Points", high_confidence)
        
        # Forecast summary
        if has_forecast and st.session_state.forecast_results is not None:
            st.subheader("üîÆ Forecast Summary")
            forecast_df = st.session_state.forecast_results
            
            if hasattr(st.session_state, 'forecast_stock_data'):
                current_price = st.session_state.forecast_stock_data['Close'].iloc[-1]
                final_price = forecast_df['Predicted_Price'].iloc[-1]
                expected_return = ((final_price - current_price) / current_price) * 100
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Current Price", f"${current_price:.2f}")
                with col2:
                    st.metric("90-Day Target", f"${final_price:.2f}")
                with col3:
                    st.metric("Expected Return", f"{expected_return:.2f}%")
        
        # LLM Analysis summary
        if has_llm_analysis:
            st.subheader("üß† AI Analysis Summary")
            llm_analysis = st.session_state.llm_forecast_analysis
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Quarter Outlook:**", llm_analysis.get('quarter_outlook', 'N/A'))
                st.write("**Confidence Level:**", f"{llm_analysis.get('confidence_level', 0):.2f}")
            
            with col2:
                correlation_strength = llm_analysis.get('sentiment_correlation_strength', 0)
                st.write("**Sentiment Correlation:**", f"{correlation_strength:.2f}")
            
            # Executive summary
            summary = llm_analysis.get('forecast_summary', '')
            if summary:
                st.subheader("Executive Summary")
                st.write(summary)
        
        # Recommendations
        st.subheader("üìà Investment Recommendations")
        
        if has_stock_data and has_sentiment and has_forecast:
            st.success("**Comprehensive Analysis Completed**")
            st.write("""
            Based on the complete analysis combining historical patterns, news sentiment, and forecasting models:
            
            1. **Historical Analysis**: Review the statistical patterns and top movements to understand volatility profiles
            2. **Sentiment Impact**: Consider the correlation between news sentiment and price movements
            3. **Forecast Reliability**: Evaluate model confidence and feature importance
            4. **Risk Management**: Use the quantile analysis for position sizing and stop-loss levels
            
            **Note**: This analysis is for educational purposes. Always conduct your own research and consider consulting with financial advisors before making investment decisions.
            """)
        else:
            st.info("Complete all analysis steps for comprehensive investment recommendations.")
        
        # Export functionality
        st.subheader("üìÑ Export Results")
        
        if st.button("üìä Generate Analysis Report"):
            # Create a comprehensive report
            report_data = {
                "analysis_date": datetime.now().isoformat(),
                "stocks_analyzed": stock_symbols,
                "analysis_period": analysis_period,
                "has_stock_data": has_stock_data,
                "has_sentiment": has_sentiment,
                "has_correlation": has_correlation,
                "has_forecast": has_forecast
            }
            
            st.json(report_data)
            st.success("Analysis report generated! Copy the JSON data above for your records.")

if __name__ == "__main__":
    main()
